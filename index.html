<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>TVI Group.</title>
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <meta content="" name="keywords">
    <meta content="" name="description">

    <!-- Favicon -->
    <link href="img/logo_fav.png" rel="icon">

    <!-- Google Web Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Heebo:wght@400;500;600&family=Nunito:wght@600;700;800&family=Pacifico&display=swap" rel="stylesheet">

    <!-- Icon Font Stylesheet -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.0/css/all.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.4.1/font/bootstrap-icons.css" rel="stylesheet">

    <!-- Libraries Stylesheet -->
    <link href="lib/animate/animate.min.css" rel="stylesheet">
    <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">
    <link href="lib/tempusdominus/css/tempusdominus-bootstrap-4.min.css" rel="stylesheet" />

    <!-- Customized Bootstrap Stylesheet -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Template Stylesheet -->
    <link href="css/style.css" rel="stylesheet">
</head>

<body>
    <div class="container-xxl bg-white p-0">
        <!-- Spinner Start -->
        <div id="spinner" class="show bg-white position-fixed translate-middle w-100 vh-100 top-50 start-50 d-flex align-items-center justify-content-center">
            <div class="spinner-border text-primary" style="width: 3rem; height: 3rem;" role="status">
                <span class="sr-only">Loading...</span>
            </div>
        </div>
        <!-- Spinner End -->


        <!-- Navbar & Hero Start -->
        <div class="container-xxl position-relative p-0">
            <nav class="navbar navbar-expand-lg navbar-dark bg-dark px-4 px-lg-5 py-3 py-lg-0">
                <a href="" class="navbar-brand p-0">
                    <!-- <h1 class="text-primary m-0"><i class="fa fa-utensils me-3"></i>IIP-XDU</h1> -->
                    <!-- <img src="img/iip_white2.png" alt="Logo"> -->
                    <img src="img/logo.png" alt="Logo" >
                </a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse">
                    <span class="fa fa-bars"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarCollapse">
                    <div class="navbar-nav ms-auto py-0 pe-4">
                        <a href="index.html" class="nav-item nav-link active">Home</a>
                        <a href="team.html" class="nav-item nav-link">Team</a>
                        <a href="research.html" class="nav-item nav-link">Research</a>
                        <!-- <a href="resources.html" class="nav-item nav-link ">Resources</a> -->
                        <a href="contact.html" class="nav-item nav-link">contact us</a>
                        <!--
                        <div class="nav-item dropdown">
                            <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown">Projects</a>
                            <div class="dropdown-menu m-0">
                                <a href="booking.html" class="dropdown-item">XAI</a>
                                <a href="team.html" class="dropdown-item">AIGC</a>
                                <a href="testimonial.html" class="dropdown-item">HIT</a>
                            </div>
                        </div>
                      -->
                         
                    </div>
                    <!-- <a href="" class="nav-item nav-link"><i class="fa fa-2x fa-language text-primary "></i></a> -->
                </div>
            </nav>

            <div class="container-xxl py-5 bg-dark hero-header mb-5 parallax hero-header">
                <div class="container text-center my-5 pt-5 pb-4">
                    <h1 class="display-3 text-white mb-3 animated slideInDown">Welcome to TVI Group</h1>
                    <nav aria-label="breadcrumb">
                        <ol class="breadcrumb justify-content-center text-uppercase">
                            <li class="breadcrumb-item"><a href="http://www.cqupt.edu.cn/" target="_blank">CQUPT</a></li>
                        </ol>
                    </nav>
                </div>
            </div>
          <!--
            <div class="container-xxl py-5 bg-dark hero-header mb-5">

                <div class="container my-5 py-5">
                    <div class="row align-items-center g-5">
                        <div class="col-lg-8 text-center text-lg-start">
                            <h1 class="display-3 text-white animated slideInLeft"> About Us </h1>
                            <p class="text-white animated slideInLeft mb-4 pb-2"> 2 papers accepted by CVPR'23</p>
                            <a href="" class="btn btn-primary py-sm-3 px-sm-5 me-3 animated slideInLeft">XAI, AIGC</a>
                        </div>
                        <div class="col-lg-4 text-center text-lg-end overflow-hidden">
                            <img class="img-fluid" src="img/hero.png" alt="">
                        </div>
                    </div>
                </div>
            </div>
          -->
        </div>
        <!-- Navbar & Hero End -->


        <!-- About Start -->
        <div class="container-xxl py-5 ">
            <div class="container">
                <div class="row g-5 align-items-center">
                    <div class="col-lg-4">
                        <div class="row g-3">
                            <div class="col-4 text-start">
                                <img class="img-fluid rounded w-100 wow zoomIn" data-wow-delay="0.1s" src="img/Ë°å‰∫∫ÂàÜÊûê.png">
                            </div>
                            <div class="col-6 text-start">
                                <img class="img-fluid rounded w-75 wow zoomIn" data-wow-delay="0.3s" src="img/ËßÜÈ¢ëÂºÇÂ∏∏.png" style="margin-top: 25%;">
                            </div>
                            <div class="col-6 text-end">
                                <img class="img-fluid rounded w-75 wow zoomIn" data-wow-delay="0.5s" src="img/Ëá™Âä®È©æÈ©∂.png">
                            </div>
                            <div class="col-6 text-end">
                                <img class="img-fluid rounded w-100 wow zoomIn" data-wow-delay="0.7s" src="img/Êú∫Ê¢∞ËáÇ.png">
                            </div>
                        </div>
                    </div>
                    <div class="col-lg-8">
                        <h5 class="section-title ff-secondary text-start text-primary fw-normal">About Us</h5>
                        <h1 class="mb-4">Trustworthy Visual Intelligence (TVI) Group</h1>
                        <p class="mb-4">The Trustworthy Visual Intelligence (TVI) group is part of the Image Cognition Group at Chongqing University of Posts and Telecommunications, a key laboratory in Chongqing. Founded in 2020, the team is a young and dynamic research group led by Associate Professor 
                            <a href="https://faculty.cqupt.edu.cn/lengjiaxu/zh_CN/index.htm"> Jiaxu Leng </a>, The group currently consists of 34 research members, focusing on Trustworthy AI, such as Video Anomaly Detection, Video Analysis, Embodied Intelligence, and Autonomous Driving.</p>
                      <p class="mb-4"> The group members have led or participated in several research projects, including the National Natural Science Foundation of China, 
                        the National Natural Science Foundation of China Youth Project, and the Chongqing Bo Xin Plan. They have published numerous academic papers in top international journals and conferences, 
                        such as NeurIPS, ACM CSUR, MM, IEEE TIFS, TMM, TITS, TCSVT, TGRS, etc.
                         </p>
                        <div class="row g-4 mb-4">
<!--                             <div class="col-sm-6">
                                <div class="d-flex align-items-center border-start border-5 border-primary px-3">
                                    <h1 class="flex-shrink-0 display-5 text-primary mb-0" data-toggle="counter-up">40</h1>
                                    <div class="ps-4">
                                        <p class="mb-0">Top/CCF-A</p>
                                        <h6 class="text-uppercase mb-0">Publications</h6>
                                    </div>
                                </div>
                            </div>
                            <div class="col-sm-6">
                                <div class="d-flex align-items-center border-start border-5 border-primary px-3">
                                    <h1 class="flex-shrink-0 display-5 text-primary mb-0" data-toggle="counter-up">25</h1>
                                    <div class="ps-4">
                                        <p class="mb-0">Phd/Master</p>
                                        <h6 class="text-uppercase mb-0">Students</h6>
                                    </div>
                                </div>
                            </div> -->
                        </div>

                    </div>
                </div>
            </div>
        </div>
        <!-- About End -->
 <!-- Vision ¬∑ Mission ¬∑ Values START -->
                 <section class="tvi-vmv-wrap" aria-labelledby="tvi-vmv-title">
  <div class="tvi-vmv-card">
    <div class="tvi-vmv-header">
      <h2 id="tvi-vmv-title" class="tvi-vmv-title">TVI ‚Äî Vision ¬∑ Mission ¬∑ Values</h2>
      <p class="tvi-vmv-sub">Trustworthy Visual Intelligence (TVI), Image Cognition Group ¬∑ Chongqing University of Posts and Telecommunications</p>
    </div>

    <div class="tvi-vmv-row">
      
      <!-- Vision -->
      <article class="tvi-vmv-item">
        <div class="tvi-vmv-icon">üöÄ</div>
        <h3>Vision</h3>
        <p>To bring trustworthy visual intelligence to real-world systems, enabling AI to understand, interpret, and act on visual information reliably across complex and dynamic environments.</p>
      </article>

      <!-- Mission -->
      <article class="tvi-vmv-item">
        <div class="tvi-vmv-icon">üß†</div>
        <h3>Mission</h3>
        <p>To advance research in trustworthy AI by developing robust and interpretable video analysis, embodied perception, and autonomous decision-making systems that align with human values and societal needs.</p>
      </article>


      <!-- Values -->
      <article class="tvi-vmv-item">
        <div class="tvi-vmv-icon">üåç</div>
        <h3>Values</h3>
        <p>We uphold collaboration, transparency, and empirical rigor. Our work emphasizes human-centered design, reproducibility, and responsible deployment of AI technologies in real-world applications.</p>
      </article>

    </div>
  </div>
</section>


                <!-- Vision ¬∑ Mission ¬∑ Values END -->
        <!-- Testimonial Start -->
        <div class="container-xxl py-5 wow fadeInUp" data-wow-delay="0.1s">
            <div class="container">
                <div class="text-center">
                    <h5 class="section-title ff-secondary text-center text-primary fw-normal">Recent News </h5>
                    <h1 class="mb-5">üéâRecent News üéâ</h1>
                </div>
                <!-- Representative News start-->
<section class="news-section" aria-label="Recent News">
  <div class="news-header">
    <div>
      <h2>Latest News</h2>
      <p>The team's latest news, events, and announcements will be continuously updated.</p>
    </div>
    
  </div>

<section class="news-section" aria-label="Recent research news">

  <div class="news-grid">
    <article class="news-card" tabindex="0" role="article" data-link="">
      <div class="news-media">
        <img src="img/2025-11.png" alt="Paper 1 illustration" />
        <time class="news-date" datetime="2025-11">2025.11</time>
      </div>
      <div class="news-body">
        <h3 class="news-title"> Two study on face super-resolution and person re-identification have been accepted by AAAI 2026  </h3>
        <p class="news-excerpt">The works were jointly supervised by Professor Xinbo Gao and Associate Professor Jiaxu Leng. The two papers focus on cross-modal person re-identification and face super-resolution in AI-computer vision, respectively.</p>
        <a class="news-cta" href="https://mp.weixin.qq.com/s/5Aq8EDMZx23OpM6fT94irA" target="_blank" rel="noopener">Read more ‚Üí</a>
      </div>
    </article>

    <article class="news-card" tabindex="0" role="article" data-link="">
      <div class="news-media">
        <img src="img/202509.webp" alt="Paper 1 illustration" />
        <time class="news-date" datetime="2025-9">2025.9</time>
      </div>
      <div class="news-body">
        <h3 class="news-title">A study on video anomaly detection was accepted by TPAMI</h3>
        <p class="news-excerpt">This study focuses on the limitations of traditional VVD and proposes the PiercingEye framework. The research was jointly supervised by Professor Xinbo  Gao and Associate Professor Jiaxu Leng.</p>
        <a class="news-cta" href="https://mp.weixin.qq.com/s/3ERM3vI2P-F_dXdBaKI2zQ" target="_blank" rel="noopener">Read more ‚Üí</a>
      </div>
    </article>

    <article class="news-card" tabindex="0" role="article" data-link="">
      <div class="news-media">
        <img src="img/2025-9.webp" alt="Paper 1 illustration" />
        <time class="news-date" datetime="2025-9">2025.9</time>
      </div>
      <div class="news-body">
        <h3 class="news-title">A study on abnormal understanding of drone aerial videos has been accepted by NeurIPS. </h3>
        <p class="news-excerpt">This paper focuses on the problem of anomaly understanding in UAV aerial video scenes and proposes the first large-scale benchmark dataset for reasoning-based UAV anomaly understanding, A2Seek.</p>
        <a class="news-cta" href="https://mp.weixin.qq.com/s/m4c0h974c4ZARyisn4LYmw" target="_blank" rel="noopener">Read more ‚Üí</a>
      </div>
    </article>



  </div>
</section>


    <!-- ... add more cards as needed -->
  </div>
</section>
                <!-- Representative News over -->
                 
<!-- All news start -->
                <!-- <div class="news-container">
                    <h2 class="news-title"></h2>
                    <div class="news-list-wrapper">
                        <ul class="news-list">
                            
                            <li><span class="news-date">[11/2025]</span> Two study on face super-resolution and person re-identification have been <strong> accepted </strong> by <strong>AAAI</strong> , a CCF A-class conference in the field of artificial intelligence.  üéâ<span class="congrats">Congratulations to Miaoqing Wang and Zhengjie Wang.</span></li>                            
                            <li><span class="news-date">[09/2025]</span> A study on video anomaly detection has been <strong> accepted </strong> by <strong> TPAMI </strong>, a CCF A-class journal in the field of artificial intelligence.  üéâ<span class="congrats">Congratulations to ZhanJie Wu.</span></li>                            
                            <li><span class="news-date">[09/2025]</span> A study on abnormal understanding of drone aerial videos has been <strong> accepted </strong>by <strong> NeurIPS </strong>, a CCF A-level conference in the field of machine learning . üéâüéâ <span class="congrats">Congratulations to Mengjingcheng Mo and Xinyang Tong.</span></li>                            
                            <li><span class="news-date">[09/2025]</span> A study on video anomaly detection has been <strong> accepted </strong> by <strong> TIP </strong>, a CCF Class A journal in the field of computer vision .üéâ <span class="congrats">Congratulations to Yumeng Zhang.</span></li>                            
                            <li><span class="news-date">[05/2025]</span> A study on pedestrian re-identification has been <strong> accepted </strong> by <strong> IEEE TIFS </strong>, a CCF-A journal in the field of information security.üéâ <span class="congrats">Congratulations to Shuang Li.</span></li>                            
                            <li><span class="news-date">[04/2025]</span> A study on small-sample object detection has been <strong> accepted </strong> by the SCI Q2 top journal <strong> Neural Networks </strong>.üéâ <span class="congrats">Congratulations to student Qianru Chen.</span></li>                            
                            <li><span class="news-date">[04/2025]</span> A study on pedestrian re-identification has been <strong> accepted </strong> by the <strong>SCI Q1 top journal Pattern Recognition </strong> .üéâ <span class="congrats">Congratulations to Shuang Li.</span></li>                            
                            <li><span class="news-date">[02/2025]</span> The multi-modal large model developed by the team has been<strong> deployed</strong> on the <strong>DeepEdge10Max </strong> and is about to become the first large model to land on the moon. üèÜ</li>
                            
                            <li><span class="news-date">[01/2025]</span> A study on video person re-identification was <strong>accepted</strong> by the CCF A-class top journal in computer vision, <strong>IJCV</strong>. üéâ <span class="congrats">Congratulations to Changjiang Kuang.</span></li>
                            <li><span class="news-date">[12/2024]</span> Awarded <strong>"Outstanding Reviewer"</strong> by the Journal of Image and Graphics. üèÜ</li>
                            <li><span class="news-date">[12/2024]</span> The review paper <strong>"Advances in Target Detection from Drone Perspectives"</strong> was <strong>awarded</strong> "Outstanding Paper of 2024". üèÖ</li>
                            <li><span class="news-date">[12/2024]</span> <strong>Approved</strong> for the New Chongqing Young Innovation Talent Program. Thanks to the support from team mentors and colleagues.</li>
                            <li><span class="news-date">[12/2024]</span> <strong>Approved</strong> for the 2024 Chongqing University of Posts and Telecommunications Large Model Innovation Team <strong>"Champion Challenge"</strong> Project.</li>
                            <li><span class="news-date">[11/2024]</span> A study on crowded pedestrian detection was <strong>accepted</strong> by the SCI Q1 TOP journal <strong>Neural Networks</strong>. üö∂‚Äç‚ôÇÔ∏è <span class="congrats">Congratulations to Feng Gao.</span></li>
                            <li><span class="news-date">[10/2024]</span> A study on crowded pedestrian detection was <strong>accepted</strong> by the SCI Q2 TOP journal <strong>Neurocomputing</strong>. <span class="congrats">Congratulations to Feng Gao.</span></li>
                            <li><span class="news-date">[09/2024]</span> A study on blind image super-resolution was <strong>accepted</strong> by the SCI Q1 TOP journal <strong>IEEE TNNLS</strong>. <span class="congrats">Congratulations to Jia Wang.</span></li>
                            <li><span class="news-date">[09/2024]</span> Achieved third place in the <strong>ECCV 2024 Autonomous Driving International Challenge</strong>. üöóüéâ <span class="congrats">Congratulations to Mengjingcheng Mo and Jingxin Wang.</span></li>
                            <li><span class="news-date">[08/2024]</span> <strong>Approved</strong> for the National Natural Science Foundation General Program. Thanks to the support from team mentors and colleagues.</li>
                            <li><span class="news-date">[07/2024]</span> <strong>Approved</strong> for four 2024 Chongqing Graduate Research Innovation Projects. <span class="congrats">Congratulations to Shuang Li, Mengjingcheng Mo, Zhanjie Wu, and Changjiang Kuang.</span></li>
                            <li><span class="news-date">[06/2024]</span> Won the <strong>only Innovation Award</strong> in the CVPR 2024 Autonomous Driving International Challenge (Application of Large Language Models in Autonomous Driving track). <span class="congrats">Congratulations to Mengjingcheng Mo and team.</span></li>
                            <li><span class="news-date">[05/2024]</span> A review paper was <strong>accepted</strong> by the SCI Q1 TOP journal <strong>ACM Computing Surveys</strong> (Impact Factor: 23.8). <span class="congrats">Congratulations to Yongming Ye and Mengjingcheng Mo.</span></li>
                            <li><span class="news-date">[03/2024]</span> Two studies on multimodal violence detection were <strong>accepted</strong> by the CCF B-class international conference <strong>ICME 2024</strong>. <span class="congrats">Congratulations to Zhanjie Wu and Yiran Liu.</span></li>
                            <li><span class="news-date">[12/2023]</span> Two undergraduate research projects were <strong>accepted</strong> by the CCF B-class international conference <strong>ICASSP 2024</strong>. <span class="congrats">Congratulations to Tianle L√º and Yuyan Chen.</span></li>
                            <li><span class="news-date">[09/2023]</span> A study on object detection was <strong>accepted</strong> by the SCI Q1 TOP international multimedia journal <strong>IEEE TMM</strong>. <span class="congrats">Congratulations to Yiran Liu.</span></li>
                            <li><span class="news-date">[07/2023]</span> A study on pedestrian detection was <strong>accepted</strong> by the CCF A-class top-tier international conference <strong>ACM MM 2023</strong>. <span class="congrats">Congratulations to Feng Gao.</span></li>

                            <li><span class="news-date">[01/2025]</span> A study on video person re-identification was <strong>accepted</strong> by the CCF A-class top journal in computer vision, <strong>IJCV</strong>. üéâ <span class="congrats">Congratulations to Changjiang Kuang.</span></li>
                            <li><span class="news-date">[12/2024]</span> Awarded <strong>"Outstanding Reviewer"</strong> by the Journal of Image and Graphics. üèÜ</li>
                            <li><span class="news-date">[12/2024]</span> The review paper <strong>"Advances in Target Detection from Drone Perspectives"</strong> was <strong>awarded</strong> "Outstanding Paper of 2024". üèÖ</li>
                            <li><span class="news-date">[12/2024]</span> <strong>Approved</strong> for the New Chongqing Young Innovation Talent Program. Thanks to the support from team mentors and colleagues.</li>
                            <li><span class="news-date">[12/2024]</span> <strong>Approved</strong> for the 2024 Chongqing University of Posts and Telecommunications Large Model Innovation Team <strong>"Champion Challenge"</strong> Project.</li>
                            <li><span class="news-date">[11/2024]</span> A study on crowded pedestrian detection was <strong>accepted</strong> by the SCI Q1 TOP journal <strong>Neural Networks</strong>. üö∂‚Äç‚ôÇÔ∏è <span class="congrats">Congratulations to Feng Gao.</span></li>
                            <li><span class="news-date">[10/2024]</span> A study on crowded pedestrian detection was <strong>accepted</strong> by the SCI Q2 TOP journal <strong>Neurocomputing</strong>. <span class="congrats">Congratulations to Feng Gao.</span></li>
                            <li><span class="news-date">[09/2024]</span> A study on blind image super-resolution was <strong>accepted</strong> by the SCI Q1 TOP journal <strong>IEEE TNNLS</strong>. <span class="congrats">Congratulations to Jia Wang.</span></li>
                            <li><span class="news-date">[09/2024]</span> Achieved third place in the <strong>ECCV 2024 Autonomous Driving International Challenge</strong>. üöóüéâ <span class="congrats">Congratulations to Mengjingcheng Mo and Jingxin Wang.</span></li>
                            <li><span class="news-date">[08/2024]</span> <strong>Approved</strong> for the National Natural Science Foundation General Program. Thanks to the support from team mentors and colleagues.</li>
                            <li><span class="news-date">[07/2024]</span> <strong>Approved</strong> for four 2024 Chongqing Graduate Research Innovation Projects. <span class="congrats">Congratulations to Shuang Li, Mengjingcheng Mo, Zhanjie Wu, and Changjiang Kuang.</span></li>
                            <li><span class="news-date">[06/2024]</span> Won the <strong>only Innovation Award</strong> in the CVPR 2024 Autonomous Driving International Challenge (Application of Large Language Models in Autonomous Driving track). <span class="congrats">Congratulations to Mengjingcheng Mo and team.</span></li>
                            <li><span class="news-date">[05/2024]</span> A review paper was <strong>accepted</strong> by the SCI Q1 TOP journal <strong>ACM Computing Surveys</strong> (Impact Factor: 23.8). <span class="congrats">Congratulations to Yongming Ye and Mengjingcheng Mo.</span></li>
                            <li><span class="news-date">[03/2024]</span> Two studies on multimodal violence detection were <strong>accepted</strong> by the CCF B-class international conference <strong>ICME 2024</strong>. <span class="congrats">Congratulations to Zhanjie Wu and Yiran Liu.</span></li>
                            <li><span class="news-date">[12/2023]</span> Two undergraduate research projects were <strong>accepted</strong> by the CCF B-class international conference <strong>ICASSP 2024</strong>. <span class="congrats">Congratulations to Tianle L√º and Yuyan Chen.</span></li>
                            <li><span class="news-date">[09/2023]</span> A study on object detection was <strong>accepted</strong> by the SCI Q1 TOP international multimedia journal <strong>IEEE TMM</strong>. <span class="congrats">Congratulations to Yiran Liu.</span></li>
                            <li><span class="news-date">[07/2023]</span> A study on pedestrian detection was <strong>accepted</strong> by the CCF A-class top-tier international conference <strong>ACM MM 2023</strong>. <span class="congrats">Congratulations to Feng Gao.</span>
                        </ul>
                    </div>
                </div> -->
                <!-- All news over -->
                </div>
               
                <!-- all achievements start -->

            <div class="text-center">
                    <h5 class="section-title ff-secondary text-center text-primary fw-normal">Research Achievements</h5>
                    <h1 class="mb-5">üèÜResearch AchievementsüèÜ</h1>
                </div>
            
                <div class="owl-carousel testimonial-carousel"  style="margin-top: 40px;">
                     <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>2 papers are accepted by AAAI!</p>
                        <p>DSCÔºöDynamic-Static Collaboration for Unsupervised Domain Adaptive Video-Based Visible-Infrared Person Re-Identificaion.PortraitSR: Artist-Inspired Prior Learning for Progressive Face Super-Resolution.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">AAAI</h5>
                                <small>2025-11</small>
                            </div>
                        </div>
                    </div>
                    
                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 paper is accepted by TIP!</p>
                        <p>DSCÔºöDynamic-Static Collaboration for Unsupervised Domain Adaptive Video-Based Visible-Infrared Person Re-Identification.Dual-space Normalizing Flow for Unsupervised Video Anomaly Detection.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">TIP</h5>
                                <small>2025-9</small>
                            </div>
                        </div>
                    </div>

                    

                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 paper is accepted by NeurIPS!</p>
                        <p>Mengjingcheng Mo, Xinyang Tong, Jiaxu Leng, Mingpi Tan, Jiankang Zheng, Yiran Liu, Haosheng Chen, Ji Gan, Weisheng Li, Xinbo Gao.A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">NeurIPS</h5>
                                <small>2025-9</small>
                            </div>
                        </div>
                    </div>

                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 paper is accepted by TPAMI (CCF-A)!</p>
                        <p>Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Mengjingcheng Mo, Jiankang Zheng, Qingqing Li, Ji Gan, Xinbo Gao.PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">TPAMI</h5>
                                <small>2025-9</small>
                            </div>
                        </div>
                    </div>

                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 study on pedestrian re-identification has been accepted by IEEE TIFS</p>
                        <p>Shuang Li, Jiaxu Leng, Changjiang Kuang, Mingpi Tan, Xinbo Gao.Video-Level Language-Driven Video-Based Visible-Infrared Person Re-Identification.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">IEEE TIFS</h5>
                                <small>2025-5</small>
                            </div>
                        </div>
                    </div>

                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 study on small-sample object detection has been accepted by the SCI Q2 top journal Neural Networks!</p>
                        <p>Jiaxu Leng, Qianru Chen, Taiyue Chen, Feng Gao,Ji Gan,Changjun Gu,Xinbo Gao.GCapNet-FSD: A Heterogeneous Graph Capsule Network for Few-Shot Object Detection.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">Neural Networks</h5>
                                <small>2025-5</small>
                            </div>
                        </div>
                    </div>

                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 study on pedestrian re-identification has been accepted by the SCI Q1 top journal Pattern Recognition!</p>
                        <p>Shuang Li, Jiaxu Leng, Ji Gan, Mengjingcheng Mo, Xinbo Gao. Shape-centered Representation Learning for Visible-Infrared Person Re-Identification.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">Pattern Recognition</h5>
                                <small>2025-4</small>
                            </div>
                        </div>
                    </div>

                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 paper is accepted by IJCV (CCF-A)!</p>
                        <p>Jiaxu Leng,  Changjiang Kuang, Shuang Li, Ji Gan, Haosheng Chen and Xinbo Gao*. Dual-Space Video Person Re-Identification[J]. International Journal of Computer Vision, 2025.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">IJCV</h5>
                                <small>2025-1</small>
                            </div>
                        </div>
                    </div>
			
                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 paper is accepted by NeurIPS (CCF-A)!</p>
                        <p>Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Yiran Liu, Ji Gan, Haosheng Chen, and Xinbo Gao*. Beyond Euclidean: Dual-Space Representation Learning for Weakly Supervised Video Violence Detection.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">NeurIPS</h5>
                                <small></small>
                            </div>
                        </div>
                    </div>
			
                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>1 paper is accepted by IEEE TNNLS (SCI Q1 TOP)!</p>
                        <p>Jiaxu Leng, Jia Wang, Mengjingcheng Mo, Ji, Gan, Wen Lu, and Xinbo Gao*. Difficulty-Guided Variant Degradation Learning for Blind Image Super-Resolution.</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">TNNLS</h5>
                                <small></small>
                            </div>
                        </div>
                    </div>
			
                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>Congratulations on achieving third place in the ECCV 2024 Autonomous Driving International Challenge, Corner Case Scene Understanding track! That's a fantastic accomplishment.!</p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">ECCV 2024 Autonomous Driving International Challenge</h5>
                                <small></small>
                            </div>
                        </div>
                    </div>
			
                    <div class="testimonial-item bg-transparent border rounded p-4">
                        <i class="fa fa-quote-left fa-2x text-primary mb-3"></i>
                        <p>A review paper has been accepted by the SCI Q1 TOP journal ACM Computing Surveys!</p>
                        <p>Jiaxu Leng, Yongming Ye, Mengjingcheng Mo, Chenqiang Gao, Ji Gan, Bin Xiao, and Xinbo Gao*. Recent Advances for Aerial Object Detection: A Survey[J]. </p>
                        <div class="d-flex align-items-center">
                            <img class="img-fluid flex-shrink-0 rounded-circle" src="img/bird.jpg" style="width: 50px; height: 50px;">
                            <div class="ps-3">
                                <h5 class="mb-1">ACM Computing Surveys</h5>
                                <small></small>
                            </div>
                        </div>
                    </div>
			
                </div>
            </div>
        </div>
                <!-- all achievements end -->


        <!-- Footer Start -->
        <div class="container-fluid bg-dark text-light footer pt-5 mt-5 wow fadeIn" data-wow-delay="0.1s">
            <div class="container py-5">
                <div class="row g-5">
                    <div class="col-lg-3 col-md-6">
                        <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Laboratory</h4>

                        <a class="btn btn-link" href="index.html" class="nav-item nav-link">About Us</a>
                        <a class="btn btn-link" href="team.html" class="nav-item nav-link">Team Members</a>
                        <a class="btn btn-link" href="research.html" class="nav-item nav-link">Research Topics</a>
                        <a class="btn btn-link" href="resources.html" class="nav-item nav-link">Resources</a>
                        <a class="btn btn-link" href="contact.html" class="nav-item nav-link">Contact Us</a>
                        <!--
                        <a class="btn btn-link" href="">Reservation</a>
                        <a class="btn btn-link" href="">Privacy Policy</a>
                        <a class="btn btn-link" href="">Terms & Condition</a>
                        <img class="flex-shrink-0 img-fluid rounded" src="img/iip_white2.png" alt="" style="width: 200px;">
                      -->

                    </div>
                    <div class="col-lg-3 col-md-6">
                        <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Contact</h4>
                        <p class="mb-2"><i class="fa fa-map-marker-alt me-3"></i>No. 2 Chongwen Road, Nan'an District, Chongqing, </p>
                        <p class="mb-2"><i class="fa fa-globe me-3"></i>CQUPT, ChongQing 10617, China</p>
                        <p class="mb-2"><i class="fa fa-envelope me-3"></i>lengjx <i class="fa fa-at"></i> cqupt.edu.cn</p>
                        <div class="d-flex pt-2">
                            <a class="btn btn-outline-light btn-social" href=""><i class="fab fa-weixin"></i></a>
                            <a class="btn btn-outline-light btn-social" href="https://github.com/OpenTVI/OpenTVI.github.io" target="_blank"><i class="fab fa-github"></i></a>
                            <!--
                            <a class="btn btn-outline-light btn-social" href=""><i class="fab fa-youtube"></i></a>
                            <a class="btn btn-outline-light btn-social" href=""><i class="fab fa-linkedin-in"></i></a>
                          -->
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6">
                        <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Links</h4>
                        <a class="btn btn-link" href="https://www.cqupt.edu.cn/" target="_blank">CQUPT</a>
                        <a class="btn btn-link" href="https://see.xidian.edu.cn/faculty/xbgao/" target="_blank">VIPSL (Xinbo Gao) </a>
                        <a class="btn btn-link" href="https://www.researchgate.net/profile/Jiaxu-Leng-2" target="_blank">Home (Jiaxu Leng) </a>
                    </div>
                    <div class="col-lg-3 col-md-6">
                        <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Pages</h4>
                        <!--
                        <p>You can try our work.</p>
                        <div class="position-relative mx-auto" style="max-width: 400px;">
                            <input class="form-control border-primary w-100 py-3 ps-4 pe-5" type="text" placeholder="Your email">
                            <button type="button" class="btn btn-primary py-2 position-absolute top-0 end-0 mt-2 me-2">SignUp</button>
                        </div>
                        <img class="img-fluid flex-shrink-0 rounded-circle" src="img/applet.png" style="width: 50px; height: 50px;">
                      -->
                        <a class="btn btn-link" href="index.html" class="nav-item nav-link">Home</a>
                        <a class="btn btn-link" href="team.html" class="nav-item nav-link">Team</a>
                        <a class="btn btn-link" href="research.html" class="nav-item nav-link">Research</a>
                        <a class="btn btn-link" href="resources.html" class="nav-item nav-link">Resources</a>
                        <a class="btn btn-link" href="contact.html" class="nav-item nav-link">Contact</a>
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="copyright">
                    <div class="row">
                        <div class="col-md-6 text-center text-md-start mb-3 mb-md-0">
                            &copy; <a class="border-bottom" href="#">TVI Group.</a>, All Right Reserved.

							<!--/*** This template is free as long as you keep the footer author‚Äôs credit link/attribution link/backlink. If you'd like to use the template without the footer author‚Äôs credit link/attribution link/backlink, you can purchase the Credit Removal License from "https://htmlcodex.com/credit-removal". Thank you for your support. ***/-->
							Designed By <a class="border-bottom" href="https://htmlcodex.com">HTML Codex</a>
                        </div>
                        <div class="col-md-6 text-center text-md-end">
                            <div class="footer-menu">
                                <a href="">Home</a>
                                <a href="">Cookies</a>
                                <a href="">Help</a>
                                <a href="">FQAs</a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Footer End -->


        <!-- Back to Top -->
        <a href="#" class="btn btn-lg btn-primary btn-lg-square back-to-top"><i class="bi bi-arrow-up"></i></a>
    </div>

    <!-- JavaScript Libraries -->
    <script src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="lib/wow/wow.min.js"></script>
    <script src="lib/easing/easing.min.js"></script>
    <script src="lib/waypoints/waypoints.min.js"></script>
    <script src="lib/counterup/counterup.min.js"></script>
    <script src="lib/owlcarousel/owl.carousel.min.js"></script>
    <script src="lib/tempusdominus/js/moment.min.js"></script>
    <script src="lib/tempusdominus/js/moment-timezone.min.js"></script>
    <script src="lib/tempusdominus/js/tempusdominus-bootstrap-4.min.js"></script>

    <!-- Template Javascript -->
    <script src="js/main.js"></script>
</body>

</html>
