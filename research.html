<!DOCTYPE html>
<html lang="en">


<head>
    <meta charset="utf-8">
    <title>TVI · Research</title>
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <meta content="" name="keywords">
    <meta content="" name="description">

    <!-- Favicon -->
    <link href="img/logo_fav.png" rel="icon">

    <!-- Google Web Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Heebo:wght@400;500;600&family=Nunito:wght@600;700;800&family=Pacifico&display=swap"
        rel="stylesheet">

    <!-- Icon Font Stylesheet -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.0/css/all.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.4.1/font/bootstrap-icons.css" rel="stylesheet">

    <!-- Libraries Stylesheet -->
    <link href="lib/animate/animate.min.css" rel="stylesheet">
    <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">
    <link href="lib/tempusdominus/css/tempusdominus-bootstrap-4.min.css" rel="stylesheet" />

    <!-- Customized Bootstrap Stylesheet -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Template Stylesheet -->
    <link href="css/style.css" rel="stylesheet">
    <style>
        .text-container {
            line-height: 1.7;
            margin-left: 30px;
        }

        .divider {
            border: none;
            border-top: 1px solid #ccc;
            /* 灰色分割线 */
            margin: 10px 0;
            /* 设置上下间距 */
        }
    </style>
</head>

<body>
    <div class="container-fluid bg-white p-0">
        <!-- Spinner Start -->
        <div id="spinner"
            class="show bg-white position-fixed translate-middle w-100 vh-100 top-50 start-50 d-flex align-items-center justify-content-center">
            <div class="spinner-border text-primary" style="width: 3rem; height: 3rem;" role="status">
                <span class="sr-only">Loading...</span>
            </div>
        </div>
        <!-- Spinner End -->



        <!-- Navbar & Hero Start -->
        <div class="container-fluid position-relative p-0">
            <nav class="navbar navbar-expand-lg navbar-dark bg-dark px-4 px-lg-5 py-3 py-lg-0">
                <a href="" class="navbar-brand p-0">
                    <!-- <h1 class="text-primary m-0"><i class="fa fa-utensils me-3"></i>IIP-XDU</h1> -->
                    <img src="img/logo.png" alt="Logo">
                </a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse">
                    <span class="fa fa-bars"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarCollapse">
                    <div class="navbar-nav ms-auto py-0 pe-4">
                        <a href="index.html" class="nav-item nav-link ">Home</a>
                        <a href="team2.html" class="nav-item nav-link ">Team</a>
                        <a href="research.html" class="nav-item nav-link active">Research</a>
                        <!-- <a href="resources.html" class="nav-item nav-link ">Resources</a> -->
                        <a href="contact.html" class="nav-item nav-link">contact us</a>
                        <!--
                        <div class="nav-item dropdown">
                            <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown">Projects</a>
                            <div class="dropdown-menu m-0">
                                <a href="booking.html" class="dropdown-item">XAI</a>
                                <a href="team2.html" class="dropdown-item">AIGC</a>
                                <a href="testimonial.html" class="dropdown-item">HIT</a>
                            </div>
                        </div>
                      -->

                    </div>
                    <!-- <a href="" class="nav-item nav-link"><i class="fa fa-2x fa-language text-primary "></i></a> -->
                </div>
            </nav>

            <div class="container-fluid py-5 bg-dark hero-header mb-5">
                <div class="container text-center my-5 pt-5 pb-4">
                    <h1 class="display-3 text-white mb-3 animated slideInDown">Research</h1>
                    <nav aria-label="breadcrumb">
                        <ol class="breadcrumb justify-content-center text-uppercase ">
                            <li class="breadcrumb-item "><a
                                    href="https://github.com/OpenTVI/OpenTVI.github.io">Github</a></li>
                            
                        </ol>
                    </nav>
                </div>
            </div>
            
        </div>
        <!-- Navbar & Hero End -->



        <!-- new：Changed the display cards of the original Research Projects -->
        <div class="text-center">
            <h5 class="section-title ff-secondary text-center text-primary fw-normal">Research</h5>
            <h1 class="mb-5">Research Projects</h1>
        </div>
        <div class="research-projects-container">
<!-- VAD start-->
            <div class="rp-card" data-url="vad2.html">

                <div class="rp-default-view">
                    <div class="rp-icon"><img src="img/vad.png" alt="Icon"></div>
                    <h3>VAD</h3>
                    <p class="rp-sub">Video Anomaly Detection</p>
                </div>

                <div class="rp-detail">
                    <!-- 任务目标 -->
                    <p class="rp-title">Objective:Enable intelligent surveillance through scene-aware anomaly learning over
                        distributed video environments.</p>
                    <!-- 任务关键词 -->
                    <div class="rp-content">
                        <div class="rp-tags">
                            <span class="rp-tag">Motion Pattern Analysis</span>
                            <span class="rp-tag">Event Detection</span>

                        </div>
                    <!-- 任务最新进展-标题 -->
                        <h3 class="rp-title">Latest development：Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance</h3>
                    <!-- 任务最新进展-简介 -->
                        <p class="rp-abstract">
                            We propose PiercingEye — a novel dual-space learning framework that integrates Euclidean and hyperbolic geometry to enhance the discriminative power of feature representations.  
                        </p>
                     <!-- read more -->
                        <div class="rp-footer">
                            <a href="vad2.html" class="rp-read-more-btn">
                                Read More
                                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                                    stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                    <path d="M5 12h14M12 5l7 7-7 7" />
                                </svg>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
<!-- VAD end -->

<!-- VIA start-->
             <div class="rp-card" data-url="vad2.html">

                <div class="rp-default-view">
                    <div class="rp-icon"><img src="img/reid.png" alt="Icon"></div>
                    <h3>VIA</h3>
                    <p class="rp-sub">Video Intelligent Analysis</p>
                </div>

                <div class="rp-detail">
                    <!-- 任务目标 -->
                    <p class="rp-title">Objective:Advancing intelligent video analysis including detection, behavior understanding and
                        re-identification.</p>
                    <!-- 任务关键词 -->
                    <div class="rp-content">
                        <div class="rp-tags">
                            <span class="rp-tag">Object Tracking</span>
                            <span class="rp-tag">Scene Understanding</span>

                        </div>
                    <!-- 任务最新进展-标题 -->
                        <h3 class="rp-title">Latest development：Dynamic-Static Collaboration for Unsupervised Domain Adaptive Video-Based Visible-Infrared Person Re-Identification</h3>
                    <!-- 任务最新进展-简介 -->
                        <p class="rp-abstract">
                            We proposed the first unsupervised domain adaptive visible-infrared video person re-identification task (UDA-VVI-ReID), and this method achieves significant results.  
                        </p>
                     <!-- read more -->
                        <div class="rp-footer">
                            <a href="reid.html" class="rp-read-more-btn">
                                Read More
                                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                                    stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                    <path d="M5 12h14M12 5l7 7-7 7" />
                                </svg>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
<!-- VIA over -->

<!-- EI start -->
              <div class="rp-card" data-url="vad2.html">

                <div class="rp-default-view">
                    <div class="rp-icon"><img src="img/jszn2.jpg" alt="Icon"></div>
                    <h3>EI</h3>
                    <p class="rp-sub">Embodied Intelligence</p>
                </div>

                <div class="rp-detail">
                    <!-- 任务目标 -->
                    <p class="rp-title">Objective:Empowering intelligent agents to learn and interact with the physical world through embodiment.</p>
                    <!-- 任务关键词 -->
                    <div class="rp-content">
                        <div class="rp-tags">
                            <span class="rp-tag">Human-Robot Interaction</span>
                            <span class="rp-tag">Adaptive Learning</span>

                        </div>
                    <!-- 任务最新进展-标题 -->
                        <h3 class="rp-title">Latest development：The team successfully developed a large-model robotic arm system called 'Wise Insight, Sharp-Eyed Quick-Hand'.</h3>
                    <!-- 任务最新进展-简介 -->
                        <p class="rp-abstract">
                            The system uses images and voice commands as input, enabling the robotic arm to accurately understand human language and perform complex tasks.
                        </p>
                     <!-- read more -->
                        <div class="rp-footer">
                            <a href="ei.html" class="rp-read-more-btn">
                                Read More
                                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                                    stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                    <path d="M5 12h14M12 5l7 7-7 7" />
                                </svg>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
<!-- EI end -->

        <div class="container-fluid py-5">
            <div class="container">
                <div class="text-center">
                    <h5 class="section-title ff-secondary text-center text-primary fw-normal">Pulications</h5>
                    <h1 class="mb-5">Selected Publications</h1>
                </div>
                <div class="d-flex align-items-center wow fadeInUp" data-wow-delay="0.1s">
                    <div class="w-100 d-flex flex-column text-start ps-4">
                        <h4 class="d-flex justify-content-between border-bottom pb-2">
                            <span>2025</span>
                            <span class="text-primary">2025</span>
                        </h4>




                        <div class="pub-item text-container">
                            <span class="pub-title ">
                                <b>PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language
                                    Guidance</b>
                                <a href="https://arxiv.org/abs/2504.18866" target="_blank">[Paper]</a>
                            </span><br>
                            <span class="pub-author">
                                Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Mengjingcheng Mo, Jiankang Zheng, Qingqing Li, Ji
                                Gan, Xinbo Gao*
                            </span><br>
                            <i class="pub-venue">
                                TPAMI, 2025 (CCF A,IF=20.8 )
                            </i>

                            <div class="pub-popup">
                                <img src="img2/2025-TPAMI.png">
                            </div>
                        </div>
                        <hr class="divider">
                        <div class="pub-item text-container">
                            <span class="pub-title ">
                                <b>A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding</b>
                                <a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/121562"
                                    target="_blank">[Paper]</a>
                            </span><br>
                            <span class="pub-author">
                                Mengjingcheng Mo · Xinyang Tong · Mingpi Tan · Jiaxu Leng · JianKang Zheng · Yiran Liu ·
                                Haosheng Chen · Ji Gan · Weisheng Li · Xinbo Gao*
                            </span><br>
                            <i class="pub-venue">
                                NeurIPS , 2025 (CCF A,SCI一区Top)
                            </i>

                            <div class="pub-popup">
                                <img src="img2/2025-NIPS_1.png">
                            </div>
                        </div>
                        <hr class="divider">
                        <div class="pub-item text-container">
                            <span class="pub-title ">
                                <b>Dual-space Normalizing Flow for Unsupervised Video Anomaly Detection</b>
                                <a href="https://ieeexplore.ieee.org/document/11185330" target="_blank">[Paper]</a>
                            </span><br>
                            <span class="pub-author">
                                Jiaxu Leng, Yumeng Zhang, Mingpi Tan, Changjiang Kuang, Zhanjie Wu, Ji Gan,Xinbo Gao*
                            </span><br>
                            <i class="pub-venue">
                                TIP , 2025 (CCF A,SCI一区Top)
                            </i>

                            <div class="pub-popup">
                                <img src="img2/2025-TIP_1.png">
                            </div>
                        </div>
                        <hr class="divider">
                        <div class="pub-item text-container">
                            <span class="pub-title ">
                                <b>Video-Level Language-Driven Video-Based Visible-Infrared Person Re-Identification</b>
                                <a href="https://arxiv.org/abs/2506.02439" target="_blank">[Paper]</a>
                            </span><br>
                            <span class="pub-author">
                                Shuang Li, Jiaxu Leng, Changjiang Kuang, Mingpi Tan, Xinbo Gao*
                            </span><br>
                            <i class="pub-venue">
                                TIFS , 2025 (CCF A,中科院一区Top)
                            </i>

                            <div class="pub-popup">
                                <img src="img2/2025-TIFS_1.png">
                            </div>
                        </div>
                        <hr class="divider">

                        <!--                         <div class="pub-item text-container">
                            <span class="pub-title ">
                                <b>GCapNet-FSD: A Heterogeneous Graph Capsule Network for Few-Shot Object Detection</b>
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608025004496"
                                    target="_blank">[Paper]</a>
                            </span><br>
                            <span class="pub-author">
                                Jiaxu Leng, Qianru Chen, Taiyue Chen, Feng Gao, Ji Gan, Changjun Gu, Xinbo Gao*
                            </span><br>
                            <i class="pub-venue">
                                Neural Networks , 2025
                            </i>

                            <div class="pub-popup">
                                <img src="img2/2025-NN_1.png">
                            </div>
                        </div>
                        <hr class="divider"> -->

                        <!-- <div class="pub-item text-container">
                            <span class="pub-title ">
                                <b>Shape-centered Representation Learning for Visible-Infrared Person Re-Identification</b>
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325004169"
                                    target="_blank">[Paper]</a>
                            </span><br>
                            <span class="pub-author">
                                Shuang Li, Jiaxu Leng, Ji Gan, Mengjingcheng Mo, Xinbo Gao*
                            </span><br>
                            <i class="pub-venue">
                                Pattern Recognition, 2025 (CCF B,中科院一区Top,IF:11.6)
                            </i>

                            <div class="pub-popup">
                                <img src="img2/2025-PR_1.png">
                            </div>
                        </div>
                        <hr class="divider"> -->
                        <div class="pub-item text-container">
                            <span class="pub-title ">
                                <b>Dual-Space Video Person Re-Identification</b>
                                <a href="https://link.springer.com/article/10.1007/s11263-025-02350-5"
                                    target="_blank">[Paper]</a>
                            </span><br>
                            <span class="pub-author">
                                Jiaxu Leng, Changjiang Kuang, Shuang Li, Ji Gan, Haosheng Chen and Xinbo Gao*
                            </span><br>
                            <i class="pub-venue">
                                International Journal of Computer Vision, 2025 (CCF A,计算机视觉领域顶级期刊，IF:11.6)
                            </i>

                            <div class="pub-popup">
                                <img src="img2/2025-ijcv_1.png">
                            </div>
                        </div>

                    </div>


                </div>



                <div class="d-flex align-items-center wow fadeInUp" data-wow-delay="0.1s">
                    <div class="w-100 d-flex flex-column text-start ps-4">
                        <h4 class="d-flex justify-content-between border-bottom pb-2">
                            <span>2024</span>
                            <span class="text-primary">2024</span>
                        </h4>
                        <div class="text-container">
                            <b>Beyond Euclidean: Dual-Space Representation Learning for Weakly Supervised Video Violence
                                Detection</b>
                            <a href="https://arxiv.org/pdf/2409.19252" target="_blank"> [ Paper ]</a><br>
                            Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Yiran Liu, Ji Gan, Haosheng Chen, and Xinbo Gao*<br>
                            <i>Advances in Neural Information Processing Systems (NeurIPS), 2024. (CCF A,
                                机器学习领域顶级会议)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>Difficulty-Guided Variant Degradation Learning for Blind Image Super-Resolution</b>
                            <a href="https://ieeexplore.ieee.org/abstract/document/10709871/" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng, Jia Wang, Mengjingcheng Mo, Ji Gan, Wen Lu, and Xinbo Gao*<br>
                            <i>IEEE Transactions on Neural Networks and Learning Systems, 2024. (SCI一区TOP, IF:10.4)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>Recent Advances for Aerial Object Detection: A Survey</b>
                            <a href="https://dl.acm.org/doi/abs/10.1145/3664598" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng, Yongming Ye, Mengjingcheng Mo, Chenqiang Gao, Ji Gan, Bin Xiao, and Xinbo
                            Gao*<br>
                            <i>ACM Computing Surveys, 2024. (SCI一区TOP, 理论计算机科学NO.1综述期刊 ，IF:23.8)</i>
                        </div>
                        <hr class="divider">
                        <div class="text-container">
                            <b>Modality-Free Violence Detection via Cross-Modal Causal Attention and Feature
                                Distillation</b>
                            <a href="https://ieeexplore.ieee.org/document/10688031" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng, Zhanjie Wu, Mengjingcheng Mo, Mingpi Tan, Shuang Li, Xinbo Gao*<br>
                            <i>IEEE International Conference on Multimedia and Expo (ICME), 2024 (CCF B,
                                多媒体领域顶级国际会议)</i>
                        </div>
                        <hr class="divider">
                        <div class="text-container">
                            <b>RC-DETR: Improving DETRs in Crowded Pedestrian Detection via Rank-Based Contrastive
                                Learning</b>
                            <a href="https://dl.acm.org/doi/10.1016/j.neunet.2024.106911?utm_source=chatgpt.com"
                                target="_blank" rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng, Yongming Ye, Mengjingcheng Mo, Chenqiang Gao, Ji Gan, Bin Xiao, and Xinbo
                            Gao*<br>
                            <i>Neural Networks, 2024. (CCF B, 人工智能领域重要期刊)</i>
                        </div>
                        <hr class="divider">
                        <!-- <ul>
                                <li>Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Yiran Liu, Ji Gan, Haosheng Chen, and Xinbo Gao*. Beyond Euclidean: Dual-Space Representation Learning for Weakly Supervised Video Violence Detection. Advances in Neural Information Processing Systems (NeurIPS), 2024.<a href="https://arxiv.org/pdf/2409.19252" target="_blank">[  Paper ]</a></li>
                                <li>
                                    Jiaxu Leng, Jia Wang, Mengjingcheng Mo, Ji, Gan, Wen Lu, and Xinbo Gao*. Difficulty-Guided Variant Degradation Learning for Blind Image Super-Resolution[J]. IEEE Transactions on Neural Networks and Learning Systems, 2024.
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10709871/" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Jiaxu Leng, Yongming Ye, Mengjingcheng Mo, Chenqiang Gao, Ji Gan, Bin Xiao, and Xinbo Gao*. Recent Advances for Aerial Object Detection: A Survey[J]. ACM Computing Surveys, 2024.
                                    <a href="https://dl.acm.org/doi/abs/10.1145/3664598" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                
                            </ul> -->
                    </div>
                </div>

                <div class="d-flex align-items-center wow fadeInUp" data-wow-delay="0.3s">
                    <div class="w-100 d-flex flex-column text-start ps-4">
                        <h4 class="d-flex justify-content-between border-bottom pb-2">
                            <span>2023</span>
                            <span class="text-primary">2023</span>
                        </h4>
                        <div class="text-container">
                            <b>CRNet: Context-guided Reasoning Network for Detecting Hard Objects</b>
                            <a href="https://ieeexplore.ieee.org/abstract/document/10252044/" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng, Yiran Liu, Xinbo Gao* and Zhihui Wang<br>
                            <i>IEEE Transactions on Multimedia, 2023. (SCI一区TOP，多媒体领域顶刊)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>Selecting Learnable Training Samples is All DETRs Need in Crowded Pedestrian
                                Detection</b>
                            <a href="https://arxiv.org/pdf/2305.10801" target="_blank" rel="noopener noreferrer"> [
                                Paper ]</a><br>
                            Feng Gao, Jiaxu Leng*, Ji Gan and Xinbo Gao*<br>
                            <i>ACM Multimedia (ACM MM) 2023. (CCF A，多媒体领域顶会)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>Characters as Graphs: Interpretable Handwritten Chinese Character Recognition via Pyramid
                                Graph Transformer</b>
                            <a href="https://www.sciencedirect.com/science/article/pii/S0031320323000183"
                                target="_blank" rel="noopener noreferrer"> [ Paper ]</a><br>
                            Ji Gan, Yuyan Chen, Bo Hu, Jiaxu Leng*, Weiqiang Wang and Xinbo Gao*<br>
                            <i>Pattern Recognition, 2023. (SCI一区TOP，人工智能领域顶刊)</i>
                        </div>
                        <hr class="divider">
                        <div class="text-container">
                            <b>Selecting Learnable Training Samples is All DETRs Need in Crowded Pedestrian
                                Detection</b>
                            <a href="https://www.sciencedirect.com/science/article/pii/S0031320323000183"
                                target="_blank" rel="noopener noreferrer"> [ Paper ]</a><br>
                            Feng Gao, Jiaxu Leng, Ji Gan, Xinbo Gao*<br>
                            <i>ACM Multimedia (ACM MM), 2023. (CCF A，多媒体领域顶会)</i>
                        </div>

                        <hr class="divider">
                        <div class="text-container">
                            <b>Contextual Learning in Fourier Complex Field for VHR Remote Sensing Images</b>
                            <a href="https://ieeexplore.ieee.org/document/10271341" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Yan Zhang, Xiyuan Gao, Qingyan Duan, Jiaxu Leng, Xiao Pu, Xinbo Gao*<br>
                            <i>IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS), 2024. (CCF A,
                                人工智能领域顶级期刊)</i>
                        </div>
                        <hr class="divider">
                        <!-- <ul>
                                <li>
                                    Jiaxu Leng, Yiran Liu, Xinbo Gao* and Zhihui Wang. CRNet: Context-guided Reasoning Network for Detecting Hard Objects[J]. IEEE Transactions on Multimedia, 2023.
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10252044/" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Feng Gao, Jiaxu Leng*, Ji Gan and Xinbo Gao*. Selecting Learnable Training Samples is All DETRs Need in Crowded Pedestrian Detection. ACM Multimedia (ACM MM) 2023.
                                    <a href="https://arxiv.org/pdf/2305.10801" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Ji Gan, Yuyan Chen, Bo Hu, Jiaxu Leng*, Weiqiang Wang and Xinbo Gao*. Characters as Graphs: Interpretable Handwritten Chinese Character Recognition via Pyramid Graph Transformer[J]. Pattern Recognition, 2023.
                                    <a href="https://www.sciencedirect.com/science/article/pii/S0031320323000183" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                            </ul> -->
                    </div>
                </div>

                <div class="d-flex align-items-center wow fadeInUp" data-wow-delay="0.5s">
                    <div class="w-100 d-flex flex-column text-start ps-4">
                        <h4 class="d-flex justify-content-between border-bottom pb-2">
                            <span>Before 2022</span>
                            <span class="text-primary">before</span>
                        </h4>
                        <div class="text-container">
                            <b>Anomaly Warning: Learning and Memorizing Future Semantic Patterns for Unsupervised
                                Ex-ante Potential Anomaly Prediction</b>
                            <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548000" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng, Mingpi Tan, Xinbo Gao*, Wen Lu and Zongyi Xu<br>
                            <i>ACM Multimedia (ACM MM), 2022. (CCF A，多媒体领域顶会)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>ICNet: Joint Alignment and Reconstruction via Iterative Collaboration for Video
                                Super-Resolution</b>
                            <a href="https://scholar.archive.org/work/in6lksficbgw5cs4lgfonucypy/access/wayback/https://dl.acm.org/doi/pdf/10.1145/3503161.3547994"
                                target="_blank" rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng, Jia Wang, Xinbo Gao*, Bo Hu, Ji Gan and Chengqiang Gao<br>
                            <i>ACM Multimedia (ACM MM), 2022. (CCF A，多媒体领域顶会)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>Pareto Refocusing for Drone-view Object Detection</b>
                            <a href="https://ieeexplore.ieee.org/abstract/document/9905640/" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng, Mengjingcheng Mo, Yinghua Zhou, Chenqiang Gao, Weisheng Li and Xinbo Gao*<br>
                            <i>IEEE Transactions on Circuits and Systems for Video Technology, 2022.
                                (SCI一区TOP，视频技术领域顶刊)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>Correlation Filter Tracker with Sample-Reliability Awareness and Self-Guided Update</b>
                            <a href="https://ieeexplore.ieee.org/abstract/document/9858918/" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Lifang Zhou, Jiaqi Li, Bangjun Lei, Weisheng Li and Jiaxu Leng*<br>
                            <i>IEEE Transactions on Circuits and Systems for Video Technology, 2022.
                                (SCI一区TOP，视频技术领域顶刊)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>HiGAN+: Handwriting Imitation GAN with Disentangled Representations</b>
                            <a href="https://dl.acm.org/doi/abs/10.1145/3550070" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Ji Gan, Weiqiang Wang*, Jiaxu Leng, Xinbo Gao*<br>
                            <i>ACM Transactions on Graphics, 2022. (SCI一区TOP，计算机图形学领域顶刊)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>CrossNet: Detecting Objects as Crosses</b>
                            <a href="https://ieeexplore.ieee.org/abstract/document/9357941/" target="_blank"
                                rel="noopener noreferrer"> [ Paper ]</a><br>
                            Jiaxu Leng*, Yin Liu, Zhihui Wang, Haibo Hu and Xinbo Gao<br>
                            <i>IEEE Transactions on Multimedia, 2021. (SCI一区TOP，多媒体领域顶刊)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>Selective Domain-invariant Feature Alignment Network for Face Anti-spoofing</b>
                            <a href="https://www.researchgate.net/profile/Jiaxu-Leng-2/publication/355920773_Selective_Domain-Invariant_Feature_Alignment_Network_for_Face_Anti-Spoofing/links/6187c5243068c54fa5ba2827/Selective-Domain-Invariant-Feature-Alignment-Network-for-Face-Anti-Spoofing.pdf"
                                target="_blank" rel="noopener noreferrer"> [ Paper ]</a><br>
                            Lifang Zhou, Jun Luo, Xinbo Gao, Weisheng Li, Bangjun Lei, and Jiaxu Leng*<br>
                            <i>IEEE Transactions on Information Forensics & Security, 2021. (SCI一区TOP，信息安全领域顶刊)</i>
                        </div>
                        <hr class="divider">

                        <div class="text-container">
                            <b>MTCNet: Multi-Task Collaboration Network for Rotation-Invariance Face Detection</b>
                            <a href="https://www.sciencedirect.com/science/article/pii/S0031320321006014"
                                target="_blank" rel="noopener noreferrer"> [ Paper ]</a><br>
                            Lifang Zhoua, Hui Zhao, Jiaxu Leng*<br>
                            <i>Pattern Recognition, 2021. (SCI一区TOP，人工智能领域顶刊)</i>
                        </div>
                        <hr class="divider">


                        <!-- <ul>
                                <li>
                                    Jiaxu Leng, Mingpi Tan, Xinbo Gao*, Wen Lu and Zongyi Xu. Anomaly Warning: Learning and Memorizing Future Semantic Patterns for Unsupervised Ex-ante Potential Anomaly Prediction. ACM Multimedia (ACM MM) 2022.
                                    <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548000" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Jiaxu Leng, Jia Wang, Xinbo Gao*, Bo Hu, Ji Gan and Chengqiang Gao. ICNet: Joint Alignment and Reconstruction via Iterative Collaboration for Video Super-Resolution. ACM Multimedia (ACM MM) 2022.
                                    <a href="https://scholar.archive.org/work/in6lksficbgw5cs4lgfonucypy/access/wayback/https://dl.acm.org/doi/pdf/10.1145/3503161.3547994" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Jiaxu Leng, Mengjingcheng Mo, Yinghua Zhou, Chenqiang Gao, Weisheng Li and Xinbo Gao*. Pareto Refocusing for Drone-view Object Detection[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2022.
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9905640/" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Lifang Zhou, Jiaqi Li, Bangjun Lei, Weisheng Li and Jiaxu Leng*. Correlation Filter Tracker with Sample-Reliability Awareness and Self-Guided Update[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2022.
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9858918/" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>

                                <li>
                                    Ji Gan, Weiqiang Wang*, Jiaxu Leng, Xinbo Gao*. HiGAN+: Handwriting Imitation GAN with Disentangled Representations[J]. ACM Transactions on Graphics, 2022, 42(1): 1-17.
                                    <a href="https://dl.acm.org/doi/abs/10.1145/3550070" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Jiaxu Leng*, Yin Liu, Zhihui Wang, Haibo Hu and Xinbo Gao. CrossNet: Detecting Objects as Crosses[J]. IEEE Transactions on Multimedia, 2021, 24: 861-875.
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9357941/" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Lifang Zhou, Jun Luo, Xinbo Gao, Weisheng Li, Bangjun Lei, and Jiaxu Leng*. Selective Domain-invariant Feature Alignment Network for Face Anti-spoofing[J]. IEEE Transactions on Information Forensics & Security, 2021.
                                    <a href="https://www.researchgate.net/profile/Jiaxu-Leng-2/publication/355920773_Selective_Domain-Invariant_Feature_Alignment_Network_for_Face_Anti-Spoofing/links/6187c5243068c54fa5ba2827/Selective-Domain-Invariant-Feature-Alignment-Network-for-Face-Anti-Spoofing.pdf" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                <li>
                                    Lifang Zhoua, Hui Zhao, Jiaxu Leng∗. MTCNet: Multi-Task Collaboration Network for Rotation-Invariance Face Detection[J]. Pattern Recognition, 2021.
                                    <a href="https://www.sciencedirect.com/science/article/pii/S0031320321006014" target="_blank" rel="noopener noreferrer">[  Paper ]</a>
                                </li>
                                
                            
                            </ul> -->
                    </div>
                </div>

            </div>

        </div>
    </div>
    <!-- Service End -->


    <!-- Footer Start -->
    <!--         <div class="container-fluid bg-dark text-light footer pt-5 mt-5 wow fadeIn" data-wow-delay="0.1s">
            <div class="container py-5">
                <div class="row g-5">
                    <div class="col-lg-3 col-md-6">
                        <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Laboratory</h4>
                        <a class="btn btn-link" href="index.html">About Us</a>
                        <a class="btn btn-link" href="contact.html">Contact Us</a>
                        <a class="btn btn-link" href="">Reservation</a>
                        <a class="btn btn-link" href="">Privacy Policy</a>
                        <a class="btn btn-link" href="">Terms & Condition</a>
                    </div>
                    <div class="col-lg-3 col-md-6">
                        <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Contact</h4>
                        <p class="mb-2"><i class="fa fa-map-marker-alt me-3"></i>No. 2 Chongwen Road, Nan'an District, Chongqing, </p>
                        <p class="mb-2"><i class="fa fa-globe me-3"></i>CQUPT, ChongQing 10617, China</p>
                        <p class="mb-2"><i class="fa fa-envelope me-3"></i>lengjx <i class="fa fa-at"></i> cqupt.edu.cn</p>
                        <div class="d-flex pt-2">
                            <a class="btn btn-outline-light btn-social" href=""><i class="fab fa-weixin"></i></a>
                            <a class="btn btn-outline-light btn-social" href="https://github.com/OpenTVI/OpenTVI.github.io" target="_blank"><i class="fab fa-github"></i></a>

                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6">
                        <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Links</h4>
                        <a class="btn btn-link" href="https://www.cqupt.edu.cn/" target="_blank">CQUPT</a>
                        <a class="btn btn-link" href="https://see.xidian.edu.cn/faculty/xbgao/" target="_blank">VIPSL (Xinbo Gao) </a>
                        <a class="btn btn-link" href="https://www.researchgate.net/profile/Jiaxu-Leng-2" target="_blank">Home (Jiaxu Leng) </a>
                    </div>
                    <div class="col-lg-3 col-md-6">
                        <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Pages</h4>
                      
                        <a class="btn btn-link" href="index.html" class="nav-item nav-link">Home</a>
                        <a class="btn btn-link" href="team2.html" class="nav-item nav-link">Team</a>
                        <a class="btn btn-link" href="research.html" class="nav-item nav-link">Research</a>
                        <a class="btn btn-link" href="resources.html" class="nav-item nav-link">Resources</a>
                        <a class="btn btn-link" href="contact.html" class="nav-item nav-link">Contact</a>
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="copyright">
                    <div class="row">
                        <div class="col-md-6 text-center text-md-start mb-3 mb-md-0">
                            &copy; <a class="border-bottom" href="#">TVI Group.</a>, All Right Reserved.

              Designed By <a class="border-bottom" href="https://htmlcodex.com">HTML Codex</a>
                        </div>
                        <div class="col-md-6 text-center text-md-end">
                            <div class="footer-menu">
                                <a href="">Home</a>
                                <a href="">Cookies</a>
                                <a href="">Help</a>
                                <a href="">FQAs</a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div> -->
    <div class="container-fluid bg-dark text-light footer pt-5 mt-5 wow fadeIn" data-wow-delay="0.1s">
        <div class="container py-5">
            <div class="row g-5">
                <div class="col-lg-3 col-md-6">
                    <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Laboratory</h4>

                    <a class="btn btn-link" href="index.html" class="nav-item nav-link">About Us</a>
                    <a class="btn btn-link" href="team2.html" class="nav-item nav-link">Team Members</a>
                    <a class="btn btn-link" href="research.html" class="nav-item nav-link">Research Topics</a>
                    <a class="btn btn-link" href="resources.html" class="nav-item nav-link">Resources</a>
                    <a class="btn btn-link" href="contact.html" class="nav-item nav-link">Contact Us</a>
                    <!--
                        <a class="btn btn-link" href="">Reservation</a>
                        <a class="btn btn-link" href="">Privacy Policy</a>
                        <a class="btn btn-link" href="">Terms & Condition</a>
                        <img class="flex-shrink-0 img-fluid rounded" src="img/iip_white2.png" alt="" style="width: 200px;">
                      -->

                </div>
                <div class="col-lg-3 col-md-6">
                    <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Contact</h4>
                    <p class="mb-2"><i class="fa fa-map-marker-alt me-3"></i>No. 2 Chongwen Road, Nan'an District,
                        Chongqing, </p>
                    <p class="mb-2"><i class="fa fa-globe me-3"></i>CQUPT, ChongQing 10617, China</p>
                    <p class="mb-2"><i class="fa fa-envelope me-3"></i>lengjx <i class="fa fa-at"></i> cqupt.edu.cn</p>
                    <div class="d-flex pt-2">
                        <a class="btn btn-outline-light btn-social" href=""><i class="fab fa-weixin"></i></a>
                        <a class="btn btn-outline-light btn-social" href="https://github.com/OpenTVI/OpenTVI.github.io"
                            target="_blank"><i class="fab fa-github"></i></a>
                        <!--
                            <a class="btn btn-outline-light btn-social" href=""><i class="fab fa-youtube"></i></a>
                            <a class="btn btn-outline-light btn-social" href=""><i class="fab fa-linkedin-in"></i></a>
                          -->
                    </div>
                </div>
                <div class="col-lg-3 col-md-6">
                    <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Links</h4>
                    <a class="btn btn-link" href="https://www.cqupt.edu.cn/" target="_blank">CQUPT</a>
                    <a class="btn btn-link" href="https://see.xidian.edu.cn/faculty/xbgao/" target="_blank">VIPSL (Xinbo
                        Gao) </a>
                    <a class="btn btn-link" href="https://www.researchgate.net/profile/Jiaxu-Leng-2"
                        target="_blank">Home (Jiaxu Leng) </a>
                </div>
                <div class="col-lg-3 col-md-6">
                    <h4 class="section-title ff-secondary text-start text-primary fw-normal mb-4">Pages</h4>
                    <!--
                        <p>You can try our work.</p>
                        <div class="position-relative mx-auto" style="max-width: 400px;">
                            <input class="form-control border-primary w-100 py-3 ps-4 pe-5" type="text" placeholder="Your email">
                            <button type="button" class="btn btn-primary py-2 position-absolute top-0 end-0 mt-2 me-2">SignUp</button>
                        </div>
                        <img class="img-fluid flex-shrink-0 rounded-circle" src="img/applet.png" style="width: 50px; height: 50px;">
                      -->
                    <a class="btn btn-link" href="index.html" class="nav-item nav-link">Home</a>
                    <a class="btn btn-link" href="team2.html" class="nav-item nav-link">Team</a>
                    <a class="btn btn-link" href="research.html" class="nav-item nav-link">Research</a>
                    <a class="btn btn-link" href="resources.html" class="nav-item nav-link">Resources</a>
                    <a class="btn btn-link" href="contact.html" class="nav-item nav-link">Contact</a>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="copyright">
                <div class="row">
                    <div class="col-md-6 text-center text-md-start mb-3 mb-md-0">
                        &copy; <a class="border-bottom" href="#">TVI Group.</a>, All Right Reserved.

                        <!--/*** This template is free as long as you keep the footer author’s credit link/attribution link/backlink. If you'd like to use the template without the footer author’s credit link/attribution link/backlink, you can purchase the Credit Removal License from "https://htmlcodex.com/credit-removal". Thank you for your support. ***/-->
                        Designed By <a class="border-bottom" href="https://htmlcodex.com">HTML Codex</a>
                    </div>
                    <div class="col-md-6 text-center text-md-end">
                        <div class="footer-menu">
                            <a href="">Home</a>
                            <a href="">Cookies</a>
                            <a href="">Help</a>
                            <a href="">FQAs</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Footer End -->


    <!-- Back to Top -->
    <a href="#" class="btn btn-lg btn-primary btn-lg-square back-to-top"><i class="bi bi-arrow-up"></i></a>
    </div>

    <!-- JavaScript Libraries -->
    <script src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="lib/wow/wow.min.js"></script>
    <script src="lib/easing/easing.min.js"></script>
    <script src="lib/waypoints/waypoints.min.js"></script>
    <script src="lib/counterup/counterup.min.js"></script>
    <script src="lib/owlcarousel/owl.carousel.min.js"></script>
    <script src="lib/tempusdominus/js/moment.min.js"></script>
    <script src="lib/tempusdominus/js/moment-timezone.min.js"></script>
    <script src="lib/tempusdominus/js/tempusdominus-bootstrap-4.min.js"></script>

    <!-- Template Javascript -->
    <script src="js/main.js"></script>
</body>

</html>